'''
Created on 13 oct. 2024

@author: robert

'''
import os
from pathlib import Path
import pandas as pd
from calendar import Calendar, monthrange

from utils import readChallengeSet
from utils import readSubmissionSet

''' https://ansperformance.eu/study/data-challenge/ '''

from utils import readParquet
from datetime import date

def q_low(x):
    return x.quantile(0.25)

def q_high(x):
    return x.quantile(0.75)

def date_iter( year, month):
    for i in range(1, monthrange(year, month)[1]  + 1):
        yield date(year, month, i)

def computeChallengeSubmission():
    
    print(''' ---------- read the challenge train dataset with True TOW values ''')
    df_challenge = readChallengeSet()
    print ( list ( df_challenge ) )
    print( df_challenge.shape )

    fileName = "final_submission_set.csv"
    df_submission = readSubmissionSet(fileName)
    print ( list ( df_submission ) )
    print( df_submission.shape )
    
    print( "--- concat challenge and submission ---")
    ''' If your index is autogenerated and you don't want to keep it, you can use the ignore_index=True option. '''
    ''' This will autogenerate a new index for you '''
    df_concat = pd.concat([df_challenge,df_submission], ignore_index=True)
    print ( df_concat.shape )
    print ( list ( df_concat ))
    return df_concat


def computeMaxAltitudes(df):
    print ("--- max Altitude feet ---")
    
    print ("--- timestamp start ---")
    df['timestampStart'] = df.groupby ( ['flight_id'] ) ['timestamp']. transform ('min')
    
    print('''--- compute high and low outliers ''')
    df['altitude_high']  = df.groupby('flight_id' , as_index=False )['altitude'] .transform(q_high)
    df['altitude_low']  = df.groupby('flight_id' , as_index=False )['altitude'] .transform(q_low)
    
    print ( "--- filter outliers ---")
    df = df.loc[ df['altitude'] < df['altitude_high'] ]
    df = df.loc[ df['altitude'] > df['altitude_low'] ]
    
    print ( "--- get max of the timestamp - Top of Descent ---")
    df['topOfDescent'] = df.groupby(['flight_id'])['timestamp'].transform('max')
    
    print ("--- start to top of descent ---")
    df['timeStarttoTopOfDescentMin'] = df.apply(lambda row: ((row['topOfDescent']-row['timestampStart'])/pd.Timedelta(minutes=1)), axis=1)
        
    df['maxAltitudeFeet'] = df.groupby ( ['flight_id'] ) ['altitude']. transform('max')
    df_maxAltitude = df.filter( items = ['flight_id', 'maxAltitudeFeet','timeStarttoTopOfDescentMin'] ).drop_duplicates()
    #print ( df_maxAltitude.shape )
    #print ( df_maxAltitude.head( 10 ))
    
    return df_maxAltitude

def computeAverageClimbRate(df):
    df_avgClimbRate = df [ ( df['vertical_rate'] >= 0.0 ) ].copy()
    df_avgClimbRate['avgClimbRateFeetMinutes'] = df_avgClimbRate.groupby ( ['flight_id'] , as_index=False ) ['vertical_rate'].transform('mean')
    df_avgClimbRate = df_avgClimbRate.filter( items = ['flight_id','avgClimbRateFeetMinutes'] ).drop_duplicates()
    #print ( df_avgClimbRate.shape )
    #print ( df_avgClimbRate.head( 10 ) )
    return df_avgClimbRate


def computeMaxClimbRate(df):
    df_maxClimbRate = df [ ( df['vertical_rate'] >= 0.0 ) ].copy()
    df_maxClimbRate['maxClimbRateFeetMinutes'] = df_maxClimbRate.groupby ( ['flight_id'] , as_index=False ) ['vertical_rate'] . transform('max')
    df_maxClimbRate = df_maxClimbRate.filter( items = ['flight_id','maxClimbRateFeetMinutes'] ).drop_duplicates()
    #print ( df_maxClimbRate.shape )
    #print ( df_maxClimbRate.head( 10 ))
    return df_maxClimbRate


def computeMaxDescentRate(df):
    df_maxDescentRate = df [ ( df['vertical_rate'] < 0.0 ) ].copy()
    df_maxDescentRate['maxDescentRateFeetMinutes'] = df_maxDescentRate.groupby( ['flight_id'] , as_index=False ) ['vertical_rate'].transform('min')
    df_maxDescentRate = df_maxDescentRate.filter( items = ['flight_id','maxDescentRateFeetMinutes'] ).drop_duplicates()
    #print ( df_maxDescentRate.shape )
    #print ( df_maxDescentRate.head( 10 ))
    return df_maxDescentRate


def computeAverageDescentRate(df):
    df_avgDescentRate = df [ ( df['vertical_rate'] <= 0.0 ) ].copy()
    df_avgDescentRate['avgDescentRateFeetMinutes'] = df_avgDescentRate.groupby ( ['flight_id'] , as_index=False ) ['vertical_rate'].transform('mean')
    df_avgDescentRate = df_avgDescentRate.filter( items = ['flight_id','avgDescentRateFeetMinutes'] ).drop_duplicates()
    #print ( df_avgDescentRate.shape )
    #print ( df_avgDescentRate.head( 10 ) )
    return df_avgDescentRate


def extendedOneDayParquet(df , df_challengeSubmission):
    
    unique_flight_ids = df['flight_id'].nunique()
    print("number of unique flight ids = {0}".format(unique_flight_ids))
    print ("number of rows = {0}".format (len(df.index)))

    ''' filter parquet on flight_id in challenge and final sumission '''
    df = df[df['flight_id'].isin(df_challengeSubmission['flight_id'])]
    
    unique_flight_ids = df['flight_id'].nunique()
    print("number of unique flight ids = {0}".format(unique_flight_ids))
    print ("number of rows = {0}".format (len(df.index)))

    
    ''' df _filtered is the final dataframe where to merge all results '''
    df_filtered = df.filter( items = ['flight_id'] ).drop_duplicates()
    
    df_maxAltitude = computeMaxAltitudes(df)
    
    df_extended = df_filtered.merge ( df_maxAltitude  , how="left" , on="flight_id")
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    #print ( df_extended.head(10))
    
    print ("--- max Climb Rate Feet Minutes ---")
    df_maxClimbRate = computeMaxClimbRate(df)
            
    df_extended = df_extended.merge( df_maxClimbRate , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    #print ( df_extended.head(10))
    
    print ("--- avg climb rate feet minutes---")
    df_avgClimbRate = computeAverageClimbRate(df)
    
    df_extended = df_extended.merge( df_avgClimbRate , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    #print ( df_extended.head(10))
            
    print ("--- max descent rate feet minutes ---")
    df_maxDescentRate = computeMaxDescentRate(df)
            
    df_extended = df_extended.merge( df_maxDescentRate , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    #print ( df_extended.head(10))
    
    print ("--- avg descent rate feet minutes---")
    df_avgDescentRate = computeAverageDescentRate(df)
    
    df_extended = df_extended.merge( df_avgDescentRate , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    #print ( df_extended.head(10))

    df['avgGroundSpeedKnots'] = df.groupby( ['flight_id'] , as_index=False ) ['groundspeed'].transform('mean')
    df_avgGroundSpeed = df.filter(items=['flight_id','avgGroundSpeedKnots']).drop_duplicates()
    #print ( df_avgGroundSpeed.head( 10 ))
            
    df_extended = df_extended.merge( df_avgGroundSpeed , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    
    df['maxGroundSpeedKnots'] = df.groupby( ['flight_id'] , as_index=False ) ['groundspeed'].transform('max')
    df_maxGroundSpeed = df.filter(items=['flight_id','maxGroundSpeedKnots']).drop_duplicates()
    #print ( df_maxGroundSpeed.head( 10 ))
            
    df_extended = df_extended.merge( df_maxGroundSpeed , how='left' , on='flight_id')
    #print ( df_extended.shape )
    #print ( list( df_extended ))
    
    print('''--- filter not a number in final dataframe ''')
    '''Extreme Gradient oost should be able to deal with NaN '''
    #df_extended.fillna(df_extended.mean(), inplace=True)
    print ( list ( df_extended ) )
    #print ( df_extended.shape )

    return df_extended
        

def extendUsingParquets(testMode=False):
    
    df_challengeSubmission = computeChallengeSubmission()
    
    first = True
    df_final = None
    yearInt = 2022
    
    if ( testMode == True ):
        theDate = date(yearInt, 1, 1)
        fileName = str(theDate) + "." + "parquet"
        df_final = extendedOneDayParquet(readParquet(fileName) , df_challengeSubmission)
    
    else:
        for iMonth in range(1,13):
            for d in date_iter( yearInt, iMonth):
                print(str( d ))
                fileName = str(d) + "." + "parquet"
            
                df = readParquet(fileName)
                if not df is None:
                    if first == True:
                        df_final = extendedOneDayParquet(df , df_challengeSubmission)
                        first = False
                    else:
                        df_extended = extendedOneDayParquet(df , df_challengeSubmission)
                        ''' ignore_index = True auto generate a new index '''
                        df_final = pd.concat ( [df_final , df_extended] , ignore_index=True)           
    
    return df_final


if __name__ == '__main__':
    
    testMode = False
    testMode = True
    df_final = extendUsingParquets(testMode)
    
    fileName = 'extendedOpenSky.parquet'
    current_dir = os.getcwd()
    
    #directoryPath = "C:\\Users\\rober\\git\\flight-profile\\trajectory\\AdsBtrajectories\\Results"
    
    directoryPath = os.path.join( current_dir , "Results" )
    directory = Path(directoryPath)
    if directory.is_dir():
            print ( "it is a directory - {0}".format(directoryPath))
            filePath = os.path.join(directory, fileName)
            ''' write the parquet file to Results '''
            if testMode == False:
                df_final.to_parquet(filePath)
            else:
                print ("--- test mode = {0}".format(testMode))
                                        
                
    print("--- its all finished ---")
    print ( df_final.shape )
    print ( list ( df_final ))
    print ( df_final.head(100))

